{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jiaj2018/code/opennet_ii/simple-dnn/simple_dnn/cnn/dcnn.py:17: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "sys.path.insert(0, os.path.abspath(\"./simple-dnn\"))\n",
    "\n",
    "#Import the libraries we will need.\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import pandas as pd\n",
    "import tensorflow.contrib.slim as slim\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import scipy.io\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "\n",
    "from util.openworld_sim import OpenWorldSim, OpenWorldMsData\n",
    "from util.visualization import visualize_dataset_2d\n",
    "from simple_dnn.cnn.dcnn import DCNN\n",
    "from simple_dnn.util.format import UnitPosNegScale, reshape_pad\n",
    "from simple_dnn.generative.vae import VariationalAutoencoder\n",
    "from simple_dnn.generative.gan import MultiClassGAN\n",
    "from simple_dnn.generative.discriminator import DiscriminatorDC\n",
    "from simple_dnn.generative.generator import GeneratorDC\n",
    "from simple_dnn.util.sample_writer import ImageGridWriter\n",
    "\n",
    "from open_net import OpenNetFlat, OpenNetCNN\n",
    "from exp_opennet_util import load_pickle_gz, save_pickle_gz, load_open_dataset\n",
    "from util.metrics import auc\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# To avoid type 3 fonts. ACM Digital library complain about this\n",
    "# based on the recomendations here http://phyletica.org/matplotlib-fonts/\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_list(pkl_files, max_fpr=1.0, use_logit_os=False):\n",
    "    auc_list = []\n",
    "    for pkl in pkl_files:\n",
    "        result = load_pickle_gz(pkl)\n",
    "        if use_logit_os: # Only for openmax model where min test_dist_all_class is not test_decision_function.\n",
    "            result_auc = auc(result['test_true_y'][:,-1], \n",
    "                               np.amin(result['test_dist_all_class'], axis=1), \n",
    "                               pos_label=1, max_fpr=max_fpr,\n",
    "                               plot=False, loc = 'lower right', \n",
    "                               figsize=[6,4], plot_threshold=False)\n",
    "        else:\n",
    "            result_auc = auc(result['test_true_y'][:,-1], \n",
    "                               result['test_decision_function'], \n",
    "                               pos_label=1, max_fpr=max_fpr,\n",
    "                               plot=False, loc = 'lower right', \n",
    "                               figsize=[6,4], plot_threshold=False)\n",
    "        auc_list.append(result_auc)\n",
    "        \n",
    "    \n",
    "    return np.array(auc_list)\n",
    "\n",
    "def acc_list(pkl_files):\n",
    "    acc_list = []\n",
    "    for pkl in pkl_files:\n",
    "        result = load_pickle_gz(pkl)\n",
    "        acc_list.append(metrics.accuracy_score(\n",
    "            np.argmax(result['test_true_y'], axis=1), result['test_closed_predict_y']))\n",
    "        \n",
    "    \n",
    "    return np.array(acc_list)\n",
    "\n",
    "\n",
    "\n",
    "def prf_list(pkl_files):\n",
    "    p_list = []\n",
    "    r_list = []\n",
    "    f_list = []\n",
    "    for pkl in pkl_files:\n",
    "        result = load_pickle_gz(pkl)\n",
    "        p, r, f, _ = metrics.precision_recall_fscore_support(\n",
    "            np.argmax(result['test_true_y'], axis=1), result['test_open_predict_y'])\n",
    "        p_list.append(p)\n",
    "        r_list.append(r)\n",
    "        f_list.append(f)\n",
    "        \n",
    "    \n",
    "    return np.array(p_list), np.array(r_list), np.array(f_list)\n",
    "\n",
    "def prf_global_threshold_list(pkl_files):\n",
    "    p_list = []\n",
    "    r_list = []\n",
    "    f_list = []\n",
    "    for pkl in pkl_files:\n",
    "        result = load_pickle_gz(pkl)\n",
    "        cutoff = max(1, int(result['train_decision_function'].shape[0] * 0.01))\n",
    "        threshold = sorted(result['train_decision_function'])[-cutoff]\n",
    "\n",
    "        pred_y = result['test_closed_predict_y']\n",
    "        score = result['test_decision_function']\n",
    "        unknown_label = len(result['class_mean'])\n",
    "        pred_y[score > threshold] = unknown_label\n",
    "\n",
    "        p, r, f, _ = metrics.precision_recall_fscore_support(\n",
    "            np.argmax(result['test_true_y'], axis=1), pred_y)\n",
    "        p_list.append(p)\n",
    "        r_list.append(r)\n",
    "        f_list.append(f)\n",
    "\n",
    "    return np.array(p_list), np.array(r_list), np.array(f_list)\n",
    "\n",
    "\n",
    "def prf_closed_list(pkl_files):\n",
    "    p_list = []\n",
    "    r_list = []\n",
    "    f_list = []\n",
    "    for pkl in pkl_files:\n",
    "        result = load_pickle_gz(pkl)\n",
    "        p, r, f, _ = metrics.precision_recall_fscore_support(\n",
    "            np.argmax(result['test_true_y'], axis=1), result['test_closed_predict_y'])\n",
    "        p_list.append(p)\n",
    "        r_list.append(r)\n",
    "        f_list.append(f)\n",
    "        \n",
    "    \n",
    "    return np.array(p_list), np.array(r_list), np.array(f_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_files(result_path, dataset, network=None, model=None, exp_id=None):\n",
    "    files = [f for f in os.listdir(result_path) if os.path.isfile(os.path.join(result_path, f))]\n",
    "    \n",
    "    dataset = dataset + '_'\n",
    "    files = [f for f in files if dataset in f]\n",
    "        \n",
    "    if network:\n",
    "        network = '_' + network + '_'\n",
    "        files = [f for f in files if network in f]\n",
    "    if model:\n",
    "        model = '_' + model + '_'\n",
    "        files = [f for f in files if model in f]\n",
    "    if exp_id:\n",
    "        exp_id = '_e' + str(exp_id) + '.'\n",
    "        files = [f for f in files if str(exp_id) in f]\n",
    "        \n",
    "    return [os.path.join(result_path, f) for f in files]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_files(result_path):\n",
    "    files = [f for f in os.listdir(result_path) if os.path.isfile(os.path.join(result_path, f))]\n",
    "    return [os.path.join(result_path, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_auc(result_dir, dataset, network, models=['ii', 'iimmf','ce', 'cemmf','triplet','tripletmmf','ceii','ceiimmf'], exp_id=None, max_fpr=1., ):\n",
    "    \"\"\"\n",
    "    use_logit_os: if True, then report using the softmax logits to for calculating outlier score. \n",
    "                    this only for Openmax models.\n",
    "    \"\"\"\n",
    "    auc_dic = {}\n",
    "    for m in models:\n",
    "        auc_dic[m] = {}\n",
    "        files = filter_files(result_dir, dataset, network=network, exp_id=exp_id,\n",
    "                             model=m if m != 'mav_dist' else 'openmax')\n",
    "        if m == 'mav_dist':\n",
    "            auc_dic[m]['auc'] = auc_list(files, max_fpr=max_fpr, use_logit_os=True)\n",
    "        else:\n",
    "            auc_dic[m]['auc'] = auc_list(files, max_fpr=max_fpr)\n",
    "        auc_dic[m]['auc_avg'] = auc_dic[m]['auc'].mean()\n",
    "        auc_dic[m]['auc_std'] = auc_dic[m]['auc'].std()\n",
    "        \n",
    "        \n",
    "    display(pd.DataFrame(auc_dic)) \n",
    "    print('AUC AVG and STD ')\n",
    "    \n",
    "    \n",
    "    ttest_p_value = {}\n",
    "    for i in range(len(models)):\n",
    "        ttest_p_value[models[i]] = {}\n",
    "        for j in range(len(models)):# range(i, len(models)):\n",
    "            _, pvalue = scipy.stats.ttest_ind(\n",
    "                auc_dic[models[i]]['auc'],\n",
    "                auc_dic[models[j]]['auc'])\n",
    "            ttest_p_value[models[i]][models[j]] = pvalue\n",
    "            \n",
    "    display(pd.DataFrame(ttest_p_value)) \n",
    "    print('T-Test PValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prf(result_dir, dataset, network, models=['ii', 'iimmf','ce', 'cemmf','triplet','tripletmmf','ceii','ceiimmf'], exp_id=None,\n",
    "#                 threshold_type='global',#'per_class'\n",
    "                bbox_to_anchor=(1,1), figsize=(16, 8), loc='upper left', ncol=8,\n",
    "                save=None, font_size=24, show_text=True, width=0.8,\n",
    "                model_label_lookup={'iimmf': 'ii+mmf', 'ii':'ii', 'ce':'ce','cemmf':'mmf+ce', 'ceiimmf':'ii+mmf+ce','ceii':'ii+ce', 'triplet':'triplet','tripletmmf':'triplet+mmf', 'openmax':' openmax', \n",
    "                                    'g_openmax':'g_openmax', 'central':'central', 'tcl': \"tcl\"},\n",
    "                openset=True, ylim=(0.2,1.1)):\n",
    "        \n",
    "    def autolabel(rects):\n",
    "        \"\"\"\n",
    "        Attach a text label above each bar displaying its height\n",
    "        \"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            plt.text(rect.get_x() + rect.get_width()/2., 1.01*height,\n",
    "                    '%.3f' % float(height),\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    \n",
    "    import matplotlib as mpl\n",
    "    font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "        'size'   : font_size}\n",
    "\n",
    "    mpl.rc('font', **font)\n",
    "    \n",
    "    prf_dic = {}\n",
    "    prf_table = {}\n",
    "    colors=[ \"purple\", \"black\", \"blue\", \"grey\", \"red\", \"green\", \"orange\", \"yellow\", \"pink\"]\n",
    "    plt.figure(figsize=figsize)\n",
    "    legend=[]\n",
    "    for i, m in enumerate(models):\n",
    "        prf_dic[m] = {}\n",
    "        prf_table[m] = {}\n",
    "        if openset:\n",
    "#             if threshold_type == 'per_class' or m == 'openmax': ## Open max does not have global threshold\n",
    "            p, r, f = prf_list(filter_files(result_dir, dataset, network=network, exp_id=exp_id, model=m))\n",
    "#             elif threshold_type == 'global':\n",
    "#                 p, r, f = prf_global_threshold_list(\n",
    "#                     filter_files(result_dir, dataset, network=network, exp_id=exp_id, model=m))\n",
    "#             else:\n",
    "#                 ValueError('threshold_type should be either \"per_class\" or \"global\"')\n",
    "        else:\n",
    "            p, r, f = prf_closed_list(filter_files(result_dir, dataset, network=network, exp_id=exp_id, model=m))\n",
    "            \n",
    "            \n",
    "        if openset:\n",
    "            prf_dic[m]['known_p_avg'] = p[:,:-1].mean(axis=1).mean()\n",
    "            prf_dic[m]['known_p_std'] = p[:,:-1].mean(axis=1).std()\n",
    "            prf_dic[m]['known_r_avg'] = r[:,:-1].mean(axis=1).mean()\n",
    "            prf_dic[m]['known_r_std'] = r[:,:-1].mean(axis=1).std()\n",
    "            prf_dic[m]['known_f_avg'] = f[:,:-1].mean(axis=1).mean()\n",
    "            prf_dic[m]['known_f_std'] = f[:,:-1].mean(axis=1).std()\n",
    "            prf_dic[m]['unknown_p_avg'] = p[:,-1].mean()\n",
    "            prf_dic[m]['unknown_p_std'] = p[:,-1].std()\n",
    "            prf_dic[m]['unknown_r_avg'] = r[:,-1].mean()\n",
    "            prf_dic[m]['unknown_r_std'] = r[:,-1].std()\n",
    "            prf_dic[m]['unknown_f_avg'] = f[:,-1].mean()\n",
    "            prf_dic[m]['unknown_f_std'] = f[:,-1].std()\n",
    "        prf_dic[m]['all_p_avg'] = p.mean(axis=1).mean()\n",
    "        prf_dic[m]['all_p_std'] = p.mean(axis=1).std()\n",
    "        prf_dic[m]['all_r_avg'] = r.mean(axis=1).mean()\n",
    "        prf_dic[m]['all_r_std'] = r.mean(axis=1).std()\n",
    "        prf_dic[m]['all_f_avg'] = f.mean(axis=1).mean()\n",
    "        prf_dic[m]['all_f_std'] = f.mean(axis=1).std()\n",
    "        prf_table[m]['Precision'] = p.mean(axis=1)\n",
    "        prf_table[m]['Recall'] = r.mean(axis=1)\n",
    "        prf_table[m]['F-Score'] = f.mean(axis=1)\n",
    "        \n",
    "        bar = plt.bar(\n",
    "            [i, i+len(models)+1, i+(len(models)+1)*2], \n",
    "            [prf_table[m]['Precision'].mean(), prf_table[m]['Recall'].mean(), prf_table[m]['F-Score'].mean()],\n",
    "            yerr=[prf_table[m]['Precision'].std(), prf_table[m]['Recall'].std(), prf_table[m]['F-Score'].std()],\n",
    "            color=colors[i], align=\"center\", width=width)\n",
    "        legend.append((bar, m if model_label_lookup is None else model_label_lookup[m]))\n",
    "        if show_text:\n",
    "            autolabel(bar)\n",
    "        \n",
    "    lgd = plt.legend(zip(*legend)[0], zip(*legend)[1], bbox_to_anchor=bbox_to_anchor, loc=loc,\n",
    "                     ncol=ncol, mode=\"expand\", borderaxespad=0.)\n",
    "    plt.xticks([ int(len(models)/2), int(len(models)/2 + len(models)+1), int(len(models)/2 + 2*(len(models)+1))], \n",
    "               [ 'Precision', 'Recall', 'F-Score'])\n",
    "    plt.ylim(ylim)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        if not os.path.exists(os.path.dirname(save)):\n",
    "            os.makedirs(os.path.dirname(save))\n",
    "        plt.savefig(save, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    mpl.rcdefaults() \n",
    "    \n",
    "    display(pd.DataFrame(prf_dic)) \n",
    "    print('PRF AVG and STD ')\n",
    "    \n",
    "    ttest_p_value = {}\n",
    "    for i in range(len(models)):\n",
    "        ttest_p_value[models[i]] = {}\n",
    "        for j in range(len(models)):# range(i, len(models)):\n",
    "            _, pvalue = scipy.stats.ttest_ind(\n",
    "                prf_table[models[i]]['F-Score'],\n",
    "                prf_table[models[j]]['F-Score'])\n",
    "            ttest_p_value[models[i]][models[j]] = pvalue\n",
    "            \n",
    "    display(pd.DataFrame(ttest_p_value)) \n",
    "    print('T-Test PValue')\n",
    "    \n",
    "# Global Threshold\n",
    "# compare_prf(mnist_cnn_dir, 'mnist', 'cnn', models=['ii', 'ce', 'ceii', 'openmax'],\n",
    "# #             save='data/results/fig/mnist_cnn_prf_all.pdf', \n",
    "#             threshold_type='global',\n",
    "#             bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=4, figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_accuracy(result_dir, dataset, network, models=['ii', 'iimmf','ce', 'cemmf','triplet','tripletmmf','ceii','ceiimmf'], exp_id=None, \n",
    "                     report_error_rate=False):\n",
    "    acc_dic = {}\n",
    "    for m in models:\n",
    "        acc_dic[m] = {}\n",
    "        files = filter_files(result_dir, dataset, network=network, exp_id=exp_id,\n",
    "                             model=m)\n",
    "        acc_dic[m]['acc'] = acc_list(files) * 100\n",
    "        if report_error_rate:\n",
    "            acc_dic[m]['acc'] = 100.0 - acc_dic[m]['acc']\n",
    "        acc_dic[m]['acc_avg'] = acc_dic[m]['acc'].mean()\n",
    "        acc_dic[m]['acc_std'] = acc_dic[m]['acc'].std()\n",
    "        \n",
    "        \n",
    "    display(pd.DataFrame(acc_dic)) \n",
    "    print('Accuracy AVG and STD ')\n",
    "    \n",
    "    \n",
    "    ttest_p_value = {}\n",
    "    for i in range(len(models)):\n",
    "        ttest_p_value[models[i]] = {}\n",
    "        for j in range(len(models)):# range(i, len(models)):\n",
    "            _, pvalue = scipy.stats.ttest_ind(\n",
    "                acc_dic[models[i]]['acc'],\n",
    "                acc_dic[models[j]]['acc'])\n",
    "            ttest_p_value[models[i]][models[j]] = pvalue\n",
    "            \n",
    "    display(pd.DataFrame(ttest_p_value)) \n",
    "    print('T-Test PValue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_time_list(pkl_files):\n",
    "    time_list = []\n",
    "    for pkl in pkl_files:\n",
    "        result = load_pickle_gz(pkl)\n",
    "        time_list.append(result['train_time'])\n",
    "        \n",
    "    return np.array(time_list)\n",
    "\n",
    "\n",
    "def compare_training_time(result_dir, dataset, network, models=['ii', 'iimmf','ce', 'cemmf','triplet','tripletmmf','ceii','ceiimmf'],):\n",
    "    t_dict = {}\n",
    "    for i, m in enumerate(models):\n",
    "        t_dict[m] = {}\n",
    "        t = training_time_list(filter_files(result_dir, dataset, network=network, model=m))\n",
    "        t_dict[m]['avg_time'] = t.mean()\n",
    "        t_dict[m]['std_time'] = t.std()\n",
    "        \n",
    "    display(pd.DataFrame(t_dict)) \n",
    "    print('Training Time AVG and STD ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(files, file_index=0, bins = 200, kde=None):\n",
    "    files = sorted(files)\n",
    "    result = load_pickle_gz(files[file_index])\n",
    "\n",
    "    x_train = result['train_decision_function'][:, None]\n",
    "    x_test = result['test_decision_function'][:, None]\n",
    "\n",
    "    # [‘gaussian’|’tophat’|’epanechnikov’|’exponential’|’linear’|’cosine’] \n",
    "    if kde:\n",
    "        kde = KernelDensity(bandwidth=1.0, algorithm='auto', kernel='gaussian', \n",
    "                            metric='euclidean', atol=0, rtol=0, breadth_first=True, \n",
    "                            leaf_size=40, metric_params=None).fit(x_train)\n",
    "    else:\n",
    "        kde = kde.fit(x_train)\n",
    "\n",
    "    print('On Training')\n",
    "    _ = plt.hist(x_train, bins=bins, normed=True)\n",
    "    xspace = np.linspace(np.amin(x_train), np.amax(x_train), 300)\n",
    "    plt.plot(xspace, np.exp(kde.score_samples(xspace[:, None])))\n",
    "    plt.show()\n",
    "\n",
    "    # On Test\n",
    "    test_unknown_mask = result['test_true_y'][:, -1].astype(bool)\n",
    "    test_known_mask = np.logical_not(test_unknown_mask)\n",
    "    x_test_known = x_test[test_known_mask]\n",
    "    x_test_unknown = x_test[test_unknown_mask]\n",
    "\n",
    "    print('On Test Known')\n",
    "    _ = plt.hist(x_test_known, bins=bins, normed=True)\n",
    "    xspace = np.linspace(np.amin(x_test_known), np.amax(x_test_known), 300)\n",
    "    plt.plot(xspace, np.exp(kde.score_samples(xspace[:, None])))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print('On Test Unknown')\n",
    "    _ = plt.hist(x_test_unknown, bins=bins, normed=True, color='red')\n",
    "    xspace = np.linspace(np.amin(x_test_unknown), np.amax(x_test), 300)\n",
    "    plt.plot(xspace, np.exp(kde.score_samples(xspace[:, None])))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaj2018/anaconda3/envs/opennet/lib/python2.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/jiaj2018/anaconda3/envs/opennet/lib/python2.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/jiaj2018/anaconda3/envs/opennet/lib/python2.7/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/jiaj2018/anaconda3/envs/opennet/lib/python2.7/site-packages/numpy/core/_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/jiaj2018/anaconda3/envs/opennet/lib/python2.7/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce</th>\n",
       "      <th>cemmf</th>\n",
       "      <th>ii</th>\n",
       "      <th>iimmf</th>\n",
       "      <th>triplet</th>\n",
       "      <th>tripletmmf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_avg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ce cemmf   ii iimmf triplet tripletmmf\n",
       "auc       []    []   []    []      []         []\n",
       "auc_avg  NaN   NaN  NaN   NaN     NaN        NaN\n",
       "auc_std  NaN   NaN  NaN   NaN     NaN        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC AVG and STD \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce</th>\n",
       "      <th>cemmf</th>\n",
       "      <th>ii</th>\n",
       "      <th>iimmf</th>\n",
       "      <th>triplet</th>\n",
       "      <th>tripletmmf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ce</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cemmf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ii</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iimmf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triplet</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripletmmf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ce  cemmf  ii  iimmf  triplet  tripletmmf\n",
       "ce         NaN    NaN NaN    NaN      NaN         NaN\n",
       "cemmf      NaN    NaN NaN    NaN      NaN         NaN\n",
       "ii         NaN    NaN NaN    NaN      NaN         NaN\n",
       "iimmf      NaN    NaN NaN    NaN      NaN         NaN\n",
       "triplet    NaN    NaN NaN    NaN      NaN         NaN\n",
       "tripletmmf NaN    NaN NaN    NaN      NaN         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Test PValue\n",
      "WARNING:tensorflow:From /home/jiaj2018/anaconda3/envs/opennet/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e032a7fdcd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#             threshold_type='global',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mfont_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=4, figsize=(17, 4))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcompare_training_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mnist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ce'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cecmmf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'triplet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tripletmmf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ii'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'iimmf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b394d89afbb4>\u001b[0m in \u001b[0;36mcompare_prf\u001b[0;34m(result_dir, dataset, network, models, exp_id, bbox_to_anchor, figsize, loc, ncol, save, font_size, show_text, width, model_label_lookup, openset, ylim)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopenset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mprf_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'known_p_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mprf_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'known_p_std'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprf_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'known_r_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1224x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = 'data/results/cnn/mnist'\n",
    "compare_auc(mnist, 'mnist', 'cnn', models=['ce','cemmf','triplet','tripletmmf','ii','iimmf'], max_fpr=1.)\n",
    "compare_prf(mnist, 'mnist', 'cnn', models=['ce','cemmf','triplet','tripletmmf','ii','iimmf'],\n",
    "    #        save='data/results/fig/mnist_cnn_prf_all.pdf', \n",
    "#             threshold_type='global', \n",
    "            font_size=17,\n",
    "            bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=4, figsize=(17, 4))\n",
    "compare_training_time(mnist, 'mnist', 'cnn', models=['ce','cecmmf','triplet','tripletmmf','ii','iimmf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = 'data/results/cnn/msadjmat'\n",
    "compare_auc(ms, 'msadjmat', 'cnn', models=['ce','cemmf','triplet','tripletmmf','ii','iimmf'], max_fpr=1.)\n",
    "compare_prf(ms, 'msadjmat', 'cnn', models=['ce','cemmf','triplet','tripletmmf','ii','iimmf'],\n",
    "        #    save='data/results/fig/msadjmat_cnn_prf_all.pdf', \n",
    "#             threshold_type='global', \n",
    "            font_size=17,\n",
    "            bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=4, figsize=(19, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android = 'data/results/flat/android'\n",
    "compare_auc(android, 'android', 'flat', models=['ce','cemmf','triplet','tripletmmf','ii','iimmf'], max_fpr=1.)\n",
    "compare_prf(android, 'android', 'flat', models=['ce','cemmf','triplet','tripletmmf','ii','iimmf'],\n",
    "    #        save='data/results/fig/android_flat_prf_all.pdf', \n",
    "#             threshold_type='global', \n",
    "            font_size=17,\n",
    "            bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=4, figsize=(19, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
